{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.7 수업 내용\n",
    "# 지난 수업 selector + 오늘 수업 Crawling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSS SELECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selector => Tag, ID(#아이디), CLASS(.클래스명)<br>\n",
    "[name = 'asdf']<br>\n",
    "[name ^= 'asdfasd']<br>\n",
    "[name $= 'asdfasd']<br>\n",
    "div p => find_all(div 찾고, 자손중에 p)<br>\n",
    "div > p => find_all(recursive = False)<br>\n",
    "div 찾고, 자식 p<br>\n",
    "div + p => find(div).find_next_sibling(P)<br>\n",
    "div태그 중 class가 article_view인 태그 탐색 body = soup.select('div.article_view')[0]<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# html 문서를 다운로드하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "\n",
    "header = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36'}\n",
    "\n",
    "def getDownload(url, params={}, retries=3):\n",
    "    resp = None\n",
    "    \n",
    "    try:\n",
    "        resp = requests.get(url, params=params, headers=header)\n",
    "        resp.raise_for_status()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if 500 <= e.response.status_code < 600 and retries > 0:\n",
    "            print(retries)\n",
    "            resp = getDownload(url, params, retries-1)\n",
    "        else:\n",
    "            print(e.response.status_code)\n",
    "            print(e.response.reason)\n",
    "            print(e.response.headers)\n",
    "            \n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다음 검색창"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = getDownload(\"https://search.daum.net/search\", {\"q\":\"박보영\"})\n",
    "daum = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://v.media.daum.net/v/20190508081336464?f=o',\n",
       " 'http://v.media.daum.net/v/20190507140359069?f=o',\n",
       " 'http://v.media.daum.net/v/20190507185002021?f=o',\n",
       " 'http://v.media.daum.net/v/20190507175700537?f=o',\n",
       " 'http://papa0717.tistory.com/223',\n",
       " 'http://dudrms606.tistory.com/367',\n",
       " 'http://adam24eve.tistory.com/858',\n",
       " 'http://k3k2y.tistory.com/35',\n",
       " 'https://ko.wikipedia.org/wiki/%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'https://ko.wikipedia.org/wiki/%EB%B0%95%EB%B3%B4%EC%98%81%20%28%EB%B2%95%EC%A1%B0%EC%9D%B8%29',\n",
       " 'http://cafe.daum.net/subdued20club/ReHf/2280152?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://cafe.daum.net/subdued20club/ReHf/2282606?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://cafe.daum.net/ASMONACOFC/gAVU/1243818?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://cafe.daum.net/ok1221/9Zdf/1524913?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://tip.daum.net/answer/54503481?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://tip.daum.net/answer/54767339?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://tip.daum.net/answer/55072609?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://tip.daum.net/answer/54866982?q=%EB%B0%95%EB%B3%B4%EC%98%81',\n",
       " 'http://gall.dcinside.com/board/lists/?id=parkboyoung',\n",
       " 'http://cafe.daum.net/parkboyoungfd',\n",
       " 'http://channels.vlive.tv/FCE49/video',\n",
       " 'http://www.bjc.or.kr/',\n",
       " 'javascript:;',\n",
       " 'javascript:;',\n",
       " 'javascript:;',\n",
       " 'javascript:;',\n",
       " 'javascript:;']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_[\"href\"] for _ in daum.select(\"div.wrap_tit > a\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 실시간 순위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = getDownload(\"https://www.naver.com/\")\n",
    "naver = BeautifulSoup(html.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한지성',\n",
       " '이인영',\n",
       " '인천공항고속도로 사고',\n",
       " '여배우 사망',\n",
       " '에어서울',\n",
       " '어버이날 문구',\n",
       " '류현진 완봉',\n",
       " '유인석',\n",
       " '한선교',\n",
       " '김태년',\n",
       " '배우 한지성',\n",
       " '완봉승',\n",
       " '오마이걸',\n",
       " '더불어민주당 원내대표',\n",
       " '밀정',\n",
       " '강은비 하나경',\n",
       " '박한별',\n",
       " '승리 구속',\n",
       " '원펀맨 2기 5화',\n",
       " '김관영',\n",
       " '한지성',\n",
       " '이인영',\n",
       " '인천공항고속도로 사고',\n",
       " '여배우 사망',\n",
       " '에어서울',\n",
       " '어버이날 문구',\n",
       " '류현진 완봉',\n",
       " '유인석',\n",
       " '한선교',\n",
       " '김태년',\n",
       " '배우 한지성',\n",
       " '완봉승',\n",
       " '오마이걸',\n",
       " '더불어민주당 원내대표',\n",
       " '밀정',\n",
       " '강은비 하나경',\n",
       " '박한별',\n",
       " '승리 구속',\n",
       " '원펀맨 2기 5화',\n",
       " '김관영']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.get_text() for _ in naver.select('.area_hotkeyword .ah_k ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한지성\n",
      "이인영\n",
      "인천공항고속도로 사고\n",
      "여배우 사망\n",
      "에어서울\n",
      "어버이날 문구\n",
      "류현진 완봉\n",
      "유인석\n",
      "한선교\n",
      "김태년\n",
      "배우 한지성\n",
      "완봉승\n",
      "오마이걸\n",
      "더불어민주당 원내대표\n",
      "밀정\n",
      "강은비 하나경\n",
      "박한별\n",
      "승리 구속\n",
      "원펀맨 2기 5화\n",
      "김관영\n"
     ]
    }
   ],
   "source": [
    "for tag in naver.select('.ah_list.PM_CL_realtimeKeyword_list_base .ah_k'):\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어들 인덱스할 것임<br>\n",
    "scrapy vs beautifulsoup 차이<br>\n",
    "scrapy는 프레임워크 bs는 라이브러리<br>\n",
    "페이지 한번 방문할 때 마다 링크를 축적해가며 다시 세팅하여 크롤한다<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling 예제 페이지!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"http://example.webscraping.com/places/default/index\"\n",
    "html = getDownload(seed)\n",
    "dom = BeautifulSoup(html.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " '/places/default/user/register?_next=/places/default/index',\n",
       " '/places/default/user/login?_next=/places/default/index',\n",
       " '/places/default/index',\n",
       " '/places/default/search',\n",
       " '/places/default/view/Afghanistan-1',\n",
       " '/places/default/view/Aland-Islands-2',\n",
       " '/places/default/view/Albania-3',\n",
       " '/places/default/view/Algeria-4',\n",
       " '/places/default/view/American-Samoa-5',\n",
       " '/places/default/view/Andorra-6',\n",
       " '/places/default/view/Angola-7',\n",
       " '/places/default/view/Anguilla-8',\n",
       " '/places/default/view/Antarctica-9',\n",
       " '/places/default/view/Antigua-and-Barbuda-10',\n",
       " '/places/default/index/1']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = [_[\"href\"] for _ in dom.select(\"a\")]\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #이면 자바스크립트 시작기호? 무시해야함 -> url 정규화 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.webscraping.com/places/default/user/register?_next=/places/default/index\n",
      "http://example.webscraping.com/places/default/user/login?_next=/places/default/index\n",
      "http://example.webscraping.com/places/default/index\n",
      "http://example.webscraping.com/places/default/search\n",
      "http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "http://example.webscraping.com/places/default/view/Albania-3\n",
      "http://example.webscraping.com/places/default/view/Algeria-4\n",
      "http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "http://example.webscraping.com/places/default/view/Andorra-6\n",
      "http://example.webscraping.com/places/default/view/Angola-7\n",
      "http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "http://example.webscraping.com/places/default/index/1\n"
     ]
    }
   ],
   "source": [
    "for link in links:\n",
    "    # # , /, http, https 가 올 것임\n",
    "    if link[0] == \"/\":\n",
    "        print(requests.compat.urljoin(seed, link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** 핵심! url 축적하면서 돌리는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "\n",
    "def urlExtractor(seed, limit):\n",
    "\n",
    "    if limit > threshold:\n",
    "        return []\n",
    "    \n",
    "    html = getDownload(seed)\n",
    "    dom = BeautifulSoup(html.content, \"lxml\")\n",
    "    \n",
    "    links = [_[\"href\"] for _ in dom.select(\"a\") if _.has_attr('href')]\n",
    "    \n",
    "    unseen = list()\n",
    "    \n",
    "    for link in links:\n",
    "        if len(link) > 1 and link[0] == \"/\":\n",
    "            newLink = requests.compat.urljoin(seed, link)            \n",
    "            if newLink not in unseen:\n",
    "                unseen.append((newLink, limit + 1))\n",
    "#             else:\n",
    "#                 print(\"Skipped2\", link)\n",
    "        # 외부로 나가는 주소\n",
    "        elif link.startswith(\"http\"):\n",
    "            unseen.append((link, limit + 1))\n",
    "#         else:    \n",
    "#             print(\"Skipped1\", link)\n",
    "            \n",
    "    return unseen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구글링크 traversal\n",
    "# 구글 검색창으로 테스트 depth(limit)는 3까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://ko.wikipedia.org/wiki/%EB%B0%95%EB%B3%B4%EC%98%81', 0),\n",
       " ('https://namu.wiki/w/%EB%B0%95%EB%B3%B4%EC%98%81', 0),\n",
       " ('https://www.msn.com/ko-kr/entertainment/news/%EB%B0%95%EB%B3%B4%EC%98%81-tvn-%EB%93%9C%EB%9D%BC%EB%A7%88-%EC%96%B4%EB%B9%84%EC%8A%A4-%EC%97%AC%EC%A3%BC%EC%9D%B8%EA%B3%B5/ar-BBLZzVh',\n",
       "  0),\n",
       " ('https://twitter.com/hashtag/%EB%B0%95%EB%B3%B4%EC%98%81', 0),\n",
       " ('https://news.joins.com/article/22895953', 0),\n",
       " ('https://www.mk.co.kr/star/hot-issues/view/2019/05/300046/', 0),\n",
       " ('https://www.mk.co.kr/star/hot-issues/view/2019/05/293931/', 0),\n",
       " ('https://www.hankyung.com/entertainment/article/201905030904H', 0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = getDownload('https://www.google.com/search', {'q':'박보영'})\n",
    "dom = BeautifulSoup(html.content, 'lxml')\n",
    "queue = [(_['href'], 0) for _ in dom.select('.r > a')]\n",
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "seen = list()\n",
    "\n",
    "# 큐가 더이상 없을때까지 돌리기\n",
    "while queue:\n",
    "    link = queue.pop(0)\n",
    "    seen.append(link[0])\n",
    "#     time.sleep(random.randint(1,3))\n",
    "    links = urlExtractor(link[0], link[1])\n",
    "    \n",
    "    queueURL = [_[0] for _ in queue]\n",
    "    queue.extend([_ for _ in links if _[0] not in queueURL \\\n",
    "                     and _ not in seen ])\n",
    "    \n",
    "    print(\"{0} {1} [{2}]\".format(\">\"*link[1], link[0], len(links)))\n",
    "#     html = download(link)\n",
    "#     dom = BeautifulSoup(html.content, 'lxml')\n",
    "    # links 는 unseen에 겹치면 안되고 seen에 있으면 안됨\n",
    "#     queue.extend([_ for _ in links if _ not in queue \\\n",
    "#                   and _ in seen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth 3으로 해서 쌓인 링크 개수 : 29790\n"
     ]
    }
   ],
   "source": [
    "print(\"depth 3으로 해서 쌓인 링크 개수 :\", len(queue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### url이 어떻게 분리되는지 보여주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='https', netloc='ko.wikipedia.org', path='/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%9D%B8%EC%9A%A9_%EC%98%A4%EB%A5%98_%EB%8F%84%EC%9B%80%EB%A7%90', params='', query='', fragment='bad_date')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.compat.urlparse(queue[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 심화 : 네이버 블로그만 크롤링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blog.naver.com'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.compat.urlparse('https://blog.naver.com/search.naver?where=post&sm=tab_jum&query=%EB%B0%95%EB%B3%B4%EC%98%81')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = getDownload('https://search.naver.com/search.naver', {'query':'박보영', \"where\":\"post\"})\n",
    "dom = BeautifulSoup(html.text, 'lxml')\n",
    "queue = [(_[\"href\"], 0) for _ in \\\n",
    "            dom.select(\"dt > a.sh_blog_title\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://blog.naver.com/js2y86?Redirect=Log&logNo=221530397718', 0),\n",
       " ('https://blog.naver.com/imagetech1?Redirect=Log&logNo=221530358950', 0),\n",
       " ('https://blog.naver.com/lyj0088?Redirect=Log&logNo=221530708253', 0),\n",
       " ('https://blog.naver.com/shkwon1128?Redirect=Log&logNo=221530738046', 0),\n",
       " ('https://komartin.blog.me/221530734469', 0),\n",
       " ('https://blog.naver.com/dlqlwm14?Redirect=Log&logNo=221529807195', 0),\n",
       " ('https://blog.naver.com/yustock1004?Redirect=Log&logNo=221531740045', 0),\n",
       " ('https://blog.naver.com/comint3?Redirect=Log&logNo=221532102016', 0),\n",
       " ('https://blog.naver.com/theboss005?Redirect=Log&logNo=221531781511', 0),\n",
       " ('https://blog.naver.com/insusul?Redirect=Log&logNo=221531749084', 0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 블로그만 크롤하게 수정한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "\n",
    "def urlExtractor(seed, limit):\n",
    "    if limit > threshold:\n",
    "        return []\n",
    "    html = getDownload(seed)\n",
    "    dom = BeautifulSoup(html.content, \"lxml\")\n",
    "\n",
    "    # iframe을 한번 더 들어가서 crawl해야 함\n",
    "    iframe = dom.select_one(\"iframe\")\n",
    "    \n",
    "    if not iframe or not iframe.has_attr(\"src\"):\n",
    "        return []\n",
    "    \n",
    "    html = getDownload(\n",
    "                requests.compat.urljoin(seed, iframe[\"src\"]))\n",
    "    dom = BeautifulSoup(html.text, 'lxml')\n",
    "    links = [_[\"href\"] for _ in dom.select(\"a\") if _.has_attr('href')]\n",
    "    \n",
    "    unseen = list()\n",
    "    \n",
    "    for link in links:\n",
    "        if len(link) > 1 and link[0] == \"/\":\n",
    "            newLink = requests.compat.urljoin(seed, link)            \n",
    "            if newLink not in unseen:\n",
    "                unseen.append((newLink, limit + 1))\n",
    "            else:\n",
    "                print(\"Skipped2\", link)\n",
    "        # 외부로 나가는 주소\n",
    "        elif link.startswith(\"http\"):\n",
    "            unseen.append((link, limit + 1))\n",
    "#         else:    \n",
    "#             print(\"Skipped1\", link)\n",
    "            \n",
    "    return unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while queue:\n",
    "    link = queue.pop(0)\n",
    "    seen.append(link[0])\n",
    "    \n",
    "#     time.sleep(random.randint(1,3))\n",
    "    links = urlExtractor(link[0], link[1])\n",
    "#     print(links)\n",
    "    queueURL = [_[0] for _ in queue]\n",
    "    queue.extend([_ for _ in links if _[0] not in queueURL \\\n",
    "                     and _[0] not in seen])\n",
    "    \n",
    "    print(\"{0} {1} [{2}]\".format(\">\"*link[1], link[0], len(links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 번외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = Gownload(\"https://arxiv.org/pdf/1708.02709.pdf\")\n",
    "with open(\"1708.02709.pdf\", \"wb\") as fp:\n",
    "    fp.write(html.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
