{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collocations : 단어의 시퀀스\n",
    "### frequency, pointwise mutual information, t test 등으로 할 것ㅇ미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "corpus = gutenberg.open(gutenberg.fileids()[0]).read()\n",
    "tokens = word_tokenize(corpus) # => 어절(구두점)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = BigramCollocationFinder.from_words(tokens)\n",
    "trigram = TrigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bigram.ngram_fd) # .items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'and'), 1880),\n",
       " (('.', \"''\"), 1157),\n",
       " ((\"''\", '``'), 959),\n",
       " ((';', 'and'), 867),\n",
       " (('to', 'be'), 593),\n",
       " ((',', \"''\"), 584),\n",
       " (('.', 'I'), 570),\n",
       " ((',', 'I'), 569),\n",
       " (('of', 'the'), 556),\n",
       " (('in', 'the'), 434)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram.ngram_fd.most_common(10) # .items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('26th', 'ult.'),\n",
       " ('Abominable', 'scoundrel'),\n",
       " ('Agricultural', 'Reports'),\n",
       " ('Austen', '1816'),\n",
       " ('Baronne', \"d'Almane\"),\n",
       " ('Candles', 'everywhere.'),\n",
       " ('Clayton', 'Park'),\n",
       " ('Comtesse', \"d'Ostalis\"),\n",
       " ('DEAR', 'MADAM'),\n",
       " ('Farmer', 'Mitchell')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram.nbest(BigramAssocMeasures.pmi, 10)\n",
    "# => 정제된(품사) 단어 쌍 ((\"형태소\", \"품사\"), \"형태소\", \"품사\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191785\n",
      "157052\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopword = stopwords.open(\"english\").read()\n",
    "pattern = re.compile(r\"[{0}]\".format(re.escape(punctuation)))\n",
    "\n",
    "print(len(tokens))\n",
    "tokens = [_ for _ in tokens if not pattern.search(_)]\n",
    "print(len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('to', 'be'), 593),\n",
       "  (('of', 'the'), 557),\n",
       "  (('in', 'the'), 434),\n",
       "  (('I', 'am'), 394),\n",
       "  (('had', 'been'), 307),\n",
       "  (('it', 'was'), 286),\n",
       "  (('I', 'have'), 281),\n",
       "  (('could', 'not'), 277),\n",
       "  (('of', 'her'), 260),\n",
       "  (('she', 'had'), 254)],\n",
       " [('Abominable', 'scoundrel'),\n",
       "  ('Agricultural', 'Reports'),\n",
       "  ('Austen', '1816'),\n",
       "  ('Clayton', 'Park'),\n",
       "  ('DEAR', 'MADAM'),\n",
       "  ('Farmer', 'Mitchell'),\n",
       "  ('Former', 'provocations'),\n",
       "  ('Hymen', 'saffron'),\n",
       "  ('Indignation', 'Abominable'),\n",
       "  ('Interference', 'fruitless')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = BigramCollocationFinder.from_words(tokens)\n",
    "trigram = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "bigram.ngram_fd.most_common(10), \\\n",
    "bigram.nbest(BigramAssocMeasures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석으로 collocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.help import upenn_tagset\n",
    "upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\"형태소\", \"품사\") 형태로 될것임\n",
    "tokens = [_[0] for _ in pos_tag(corpus) if not pattern.search(_[0])] # 1로 바꿔서 하면 품사빈도를 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848809"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('to', 'be'), 593),\n",
       "  (('of', 'the'), 557),\n",
       "  (('in', 'the'), 434),\n",
       "  (('I', 'am'), 394),\n",
       "  (('had', 'been'), 307),\n",
       "  (('it', 'was'), 286),\n",
       "  (('I', 'have'), 281),\n",
       "  (('could', 'not'), 277),\n",
       "  (('of', 'her'), 260),\n",
       "  (('she', 'had'), 254)],\n",
       " [('Abominable', 'scoundrel'),\n",
       "  ('Agricultural', 'Reports'),\n",
       "  ('Austen', '1816'),\n",
       "  ('Clayton', 'Park'),\n",
       "  ('DEAR', 'MADAM'),\n",
       "  ('Farmer', 'Mitchell'),\n",
       "  ('Former', 'provocations'),\n",
       "  ('Hymen', 'saffron'),\n",
       "  ('Indignation', 'Abominable'),\n",
       "  ('Interference', 'fruitless')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = BigramCollocationFinder.from_words(tokens)\n",
    "trigram = TrigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "bigram.ngram_fd.most_common(10), \\\n",
    "bigram.nbest(BigramAssocMeasures.pmi, 10)\n",
    "\n",
    "# 결과가 거의 똑같이 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kolaw\n",
    "from konlpy.tag import Komoran\n",
    "corpus = kolaw.open(kolaw.fileids()[0]).read()\n",
    "tokens = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('있다', '.'), 57),\n",
       "  (('한다', '.'), 56),\n",
       "  (('수', '있다'), 56),\n",
       "  (('법률이', '정하는'), 48),\n",
       "  (('정하는', '바에'), 37),\n",
       "  (('바에', '의하여'), 36),\n",
       "  (('법률로', '정한다'), 28),\n",
       "  (('정한다', '.'), 28),\n",
       "  (('가진다', '.'), 25),\n",
       "  (('아니한다', '.'), 25)],\n",
       " [(\"''\", '제70조'),\n",
       "  ('12일에', '제정되고'),\n",
       "  ('1948년', '7월'),\n",
       "  ('1987.10.29.', '>'),\n",
       "  ('1988년', '2월'),\n",
       "  ('1인과', '부의장'),\n",
       "  ('1회', '집회되며'),\n",
       "  ('200인', '이상으로'),\n",
       "  ('20일을', '경과함으로써'),\n",
       "  ('25일부터', '시행한다')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)\n",
    "bigram = BigramCollocationFinder.from_words(tokens)\n",
    "bigram.ngram_fd.most_common(10), \\\n",
    "bigram.nbest(BigramAssocMeasures.chi_sq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = Komoran().pos\n",
    "pos = list()\n",
    "for _ in tokens:\n",
    "    if not pattern.search(_):\n",
    "        pos.extend(ma(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4640, 9337)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), len(pos) # 한글은 형태소 분석하면 늘어남 형태소 단위라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([((('ㄴ다', 'EC'), ('제', 'XPN')), 89),\n",
       "  ((('에', 'JKB'), ('의하', 'VV')), 83),\n",
       "  ((('ㄹ', 'ETM'), ('수', 'NNB')), 79),\n",
       "  ((('조', 'NR'), ('①', 'SW')), 78),\n",
       "  ((('하', 'XSV'), ('ㄹ', 'ETM')), 76),\n",
       "  ((('의하', 'VV'), ('아', 'EC')), 66),\n",
       "  ((('수', 'NNB'), ('있', 'VV')), 64),\n",
       "  ((('하', 'XSV'), ('ㄴ다', 'EC')), 58),\n",
       "  ((('법률', 'NNG'), ('이', 'JKS')), 57),\n",
       "  ((('이', 'JKS'), ('정하', 'VV')), 57)],\n",
       " [(('가부', 'NNP'), ('동수', 'NNP')),\n",
       "  (('강제', 'NNG'), ('노역', 'NNG')),\n",
       "  (('경자', 'NNP'), ('유전', 'NNP')),\n",
       "  (('교전', 'NNG'), ('상태', 'NNG')),\n",
       "  (('국립', 'NNP'), ('대학교', 'NNG')),\n",
       "  (('군', 'NNB'), ('참모총장', 'NNP')),\n",
       "  (('군용', 'NNG'), ('물', 'NNG')),\n",
       "  (('궐위되거나', 'NA'), ('사고', 'NNG')),\n",
       "  (('기', 'NNG'), ('망', 'NNG')),\n",
       "  (('기간', 'NNP'), ('내', 'NNB'))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = BigramCollocationFinder.from_words(pos)\n",
    "bigram.ngram_fd.most_common(10), \\\n",
    "bigram.nbest(BigramAssocMeasures.chi_sq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([((('에', 'JKB'), ('의하', 'VV'), ('아', 'EC')), 66),\n",
       "  ((('하', 'XSV'), ('ㄹ', 'ETM'), ('수', 'NNB')), 56),\n",
       "  ((('ㄹ', 'ETM'), ('수', 'NNB'), ('있', 'VV')), 56),\n",
       "  ((('수', 'NNB'), ('있', 'VV'), ('다', 'EC')), 56),\n",
       "  ((('법률', 'NNG'), ('이', 'JKS'), ('정하', 'VV')), 55),\n",
       "  ((('이', 'JKS'), ('정하', 'VV'), ('는', 'ETM')), 50),\n",
       "  ((('때', 'NNG'), ('에', 'JKB'), ('는', 'JX')), 42),\n",
       "  ((('에', 'JKB'), ('관하', 'VV'), ('ㄴ', 'ETM')), 38),\n",
       "  ((('정하', 'VV'), ('는', 'ETM'), ('바', 'NNB')), 37),\n",
       "  ((('는', 'ETM'), ('바', 'NNB'), ('에', 'JKB')), 37)],\n",
       " [(('주요', 'XR'), ('방위', 'NNG'), ('산업체', 'NNG')),\n",
       "  (('최고', 'NNP'), ('도로', 'NNP'), ('발휘', 'NNG')),\n",
       "  (('유독', 'NNG'), ('음식물', 'NNG'), ('공급', 'NNP')),\n",
       "  (('과학기술', 'NNP'), ('자와', 'NNP'), ('예술가', 'NNP')),\n",
       "  (('국립', 'NNP'), ('대학교', 'NNG'), ('총장', 'NNP')),\n",
       "  (('심사', 'NNP'), ('16', 'SN'), ('검찰', 'NNG')),\n",
       "  (('우호', 'NNG'), ('통상항해조약', 'NNP'), ('주권', 'NNP')),\n",
       "  (('하고', 'JKB'), ('외교', 'NNG'), ('사절', 'NNG')),\n",
       "  (('호', 'NNB'), ('부칙', 'NNP'), ('보기', 'NNP')),\n",
       "  (('각', 'MM'), ('군', 'NNB'), ('참모총장', 'NNP'))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram = TrigramCollocationFinder.from_words(pos)\n",
    "trigram.ngram_fd.most_common(10), \\\n",
    "trigram.nbest(TrigramAssocMeasures.chi_sq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('하', 'ㄴ다'), 114),\n",
       "  (('하', 'ㄹ'), 92),\n",
       "  (('ㄴ다', '제'), 89),\n",
       "  (('하', 'ㄴ'), 88),\n",
       "  (('에', '의하'), 83),\n",
       "  (('ㄹ', '수'), 79),\n",
       "  (('조', '①'), 78),\n",
       "  (('의하', '아'), 66),\n",
       "  (('수', '있'), 64),\n",
       "  (('법률', '이'), 59)],\n",
       " [('가부', '동수'),\n",
       "  ('강제', '노역'),\n",
       "  ('경자', '유전'),\n",
       "  ('교전', '상태'),\n",
       "  ('국립', '대학교'),\n",
       "  ('군', '참모총장'),\n",
       "  ('군용', '물'),\n",
       "  ('궐위되거나', '사고'),\n",
       "  ('내부', '규율'),\n",
       "  ('더욱', '확고히')])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morphemes = [_[0] for _ in pos]\n",
    "_pos = [_[1] for _ in pos]\n",
    "\n",
    "bigram = BigramCollocationFinder.from_words(morphemes)\n",
    "bigram.ngram_fd.most_common(10), \\\n",
    "bigram.nbest(BigramAssocMeasures.chi_sq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EC': '연결 어미',\n",
       " 'EF': '종결 어미',\n",
       " 'EP': '선어말어미',\n",
       " 'ETM': '관형형 전성 어미',\n",
       " 'ETN': '명사형 전성 어미',\n",
       " 'IC': '감탄사',\n",
       " 'JC': '접속 조사',\n",
       " 'JKB': '부사격 조사',\n",
       " 'JKC': '보격 조사',\n",
       " 'JKG': '관형격 조사',\n",
       " 'JKO': '목적격 조사',\n",
       " 'JKQ': '인용격 조사',\n",
       " 'JKS': '주격 조사',\n",
       " 'JKV': '호격 조사',\n",
       " 'JX': '보조사',\n",
       " 'MAG': '일반 부사',\n",
       " 'MAJ': '접속 부사',\n",
       " 'MM': '관형사',\n",
       " 'NA': '분석불능범주',\n",
       " 'NF': '명사추정범주',\n",
       " 'NNB': '의존 명사',\n",
       " 'NNG': '일반 명사',\n",
       " 'NNP': '고유 명사',\n",
       " 'NP': '대명사',\n",
       " 'NR': '수사',\n",
       " 'NV': '용언추정범주',\n",
       " 'SE': '줄임표',\n",
       " 'SF': '마침표, 물음표, 느낌표',\n",
       " 'SH': '한자',\n",
       " 'SL': '외국어',\n",
       " 'SN': '숫자',\n",
       " 'SO': '붙임표(물결,숨김,빠짐)',\n",
       " 'SP': '쉼표,가운뎃점,콜론,빗금',\n",
       " 'SS': '따옴표,괄호표,줄표',\n",
       " 'SW': '기타기호 (논리수학기호,화폐기호)',\n",
       " 'VA': '형용사',\n",
       " 'VCN': '부정 지정사',\n",
       " 'VCP': '긍정 지정사',\n",
       " 'VV': '동사',\n",
       " 'VX': '보조 용언',\n",
       " 'XPN': '체언 접두사',\n",
       " 'XR': '어근',\n",
       " 'XSA': '형용사 파생 접미사',\n",
       " 'XSN': '명사파생 접미사',\n",
       " 'XSV': '동사 파생 접미사'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Komoran().tagset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스기사로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base = \"./news_crawl_project/\"\n",
    "morphemes = list()\n",
    "tokens = list()\n",
    "    \n",
    "for _ in os.listdir(base):\n",
    "    with open(base + _, encoding='utf-8') as fp:\n",
    "        text = fp.read()\n",
    "    tokens.extend(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['━4개',\n",
       " '과로',\n",
       " '구성된',\n",
       " \"'우주국\",\n",
       " \"'\",\n",
       " '검토과학기술정보통신부가',\n",
       " '우주탐사와',\n",
       " '관련',\n",
       " '산업',\n",
       " '육성을',\n",
       " '위한',\n",
       " '‘',\n",
       " '우주청',\n",
       " '’',\n",
       " '설립을',\n",
       " '준비하고',\n",
       " '있다',\n",
       " '.',\n",
       " '하지만',\n",
       " ',']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = Komoran().pos\n",
    "pos = list()\n",
    "for _ in tokens:\n",
    "    if not pattern.search(_):\n",
    "        pos.extend(ma(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([((('았', 'EP'), ('다', 'EC')), 5377),\n",
       "  ((('하', 'XSV'), ('았', 'EP')), 4892),\n",
       "  ((('하', 'XSV'), ('ㄴ', 'ETM')), 4414),\n",
       "  ((('었', 'EP'), ('다', 'EC')), 3369),\n",
       "  ((('고', 'EC'), ('있', 'VV')), 2774),\n",
       "  ((('하', 'XSV'), ('는', 'ETM')), 2655),\n",
       "  ((('이', 'VCP'), ('ㄴ', 'ETM')), 2488),\n",
       "  ((('있', 'VV'), ('다', 'EC')), 2458),\n",
       "  ((('하', 'XSV'), ('아', 'EC')), 2428),\n",
       "  ((('하', 'XSV'), ('ㄹ', 'ETM')), 2360)],\n",
       " [(('123', 'NNP'), ('sunhyung', 'SL')),\n",
       "  (('1630년대', 'NNP'), ('튤립', 'NNP')),\n",
       "  (('1888', 'SN'), ('ps', 'SL')),\n",
       "  (('1호선', 'NNP'), ('서면역', 'NNP')),\n",
       "  (('4K', 'NNP'), ('UHD', 'SL')),\n",
       "  (('8199', 'SN'), ('한동희', 'NA')),\n",
       "  (('972', 'SN'), ('㎿', 'SH')),\n",
       "  (('AOA', 'SL'), ('민아', 'NNP')),\n",
       "  (('Agir', 'SL'), ('베르트랑', 'NNP')),\n",
       "  (('Alan', 'SL'), ('Randell', 'SL'))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram = BigramCollocationFinder.from_words(pos)\n",
    "bigram.ngram_fd.most_common(10), \\\n",
    "bigram.nbest(BigramAssocMeasures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('하', 'ㄴ'), 6256),\n",
       "  (('하', '았'), 5924),\n",
       "  (('았', '다'), 5385),\n",
       "  (('었', '다'), 3406),\n",
       "  (('하', '는'), 3170),\n",
       "  (('하', 'ㄹ'), 2924),\n",
       "  (('하', '아'), 2874),\n",
       "  (('고', '있'), 2829),\n",
       "  (('하', '고'), 2698),\n",
       "  (('이', 'ㄴ'), 2535)],\n",
       " [('1630년대', '튤립'),\n",
       "  ('1888', 'ps'),\n",
       "  ('1호선', '서면역'),\n",
       "  ('4K', 'UHD'),\n",
       "  ('6010', 'KP'),\n",
       "  ('8199', '한동희'),\n",
       "  ('972', '㎿'),\n",
       "  ('AOA', '민아'),\n",
       "  ('AT', 'T'),\n",
       "  ('AURA', 'SYNC')])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morphemes = [_[0] for _ in pos]\n",
    "_pos = [_[1] for _ in pos]\n",
    "\n",
    "bigram = BigramCollocationFinder.from_words(morphemes)\n",
    "bigram.ngram_fd.most_common(10), \\\n",
    "bigram.nbest(BigramAssocMeasures.chi_sq, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pharse 구문분석\n",
    "### 트리의 형태로 분석\n",
    "### re를 이용하고 그걸로 parser 할 것임\n",
    "### 단어레벨보다 더 높은 레벨에서 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The little yellow dog barked at the cat\"\n",
    "tokens = pos_tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('yellow', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cat', 'NN')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n"
     ]
    }
   ],
   "source": [
    "upenn_tagset(\"VBD\") # 품사태거 우리나라는 세종 21, 형태소분석기마닥 다르므로 따로 봐야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk.regexp import RegexpParser\n",
    "\n",
    "grammer = RegexpParser(\"NP: {<DT><NN>}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n"
     ]
    }
   ],
   "source": [
    "grammer = RegexpParser(\"NP: {<DT><JJ>*<NN>}\")\n",
    "parseTree = grammer.parse(tokens)\n",
    "parseTree.draw()\n",
    "parseTree.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (DT The/DT) (JJ little/JJ) (JJ yellow/JJ) (NN dog/NN))\n",
      "  (VBD barked/VBD)\n",
      "  (IN at/IN)\n",
      "  (NP (DT the/DT) (NN cat/NN)))\n"
     ]
    }
   ],
   "source": [
    "grammer = RegexpParser(\"\"\"\n",
    "    DT: {<DT>}\n",
    "    JJ: {<JJ>}\n",
    "    NN: {<NN>}\n",
    "    VBD: {<VBD>}\n",
    "    IN: {<IN>}\n",
    "    NP: {<DT><JJ>*<NN>}\n",
    "\"\"\")\n",
    "parseTree = grammer.parse(tokens)\n",
    "parseTree.draw()\n",
    "parseTree.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([_ for _ in parseTree.subtrees()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP\n",
      "The little yellow dog\n",
      "NP\n",
      "the cat\n"
     ]
    }
   ],
   "source": [
    "for _ in parseTree.subtrees():\n",
    "    if _.label() == \"NP\":\n",
    "        print(_.label())\n",
    "        print(\" \".join([_[0] for _ in _.leaves()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 구문분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "ma = Okt().pos\n",
    "\n",
    "sentence = \"내 친구가 잠을 많이 잔다.\"\n",
    "tokens = ma(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('내', 'Noun'),\n",
       " ('친구', 'Noun'),\n",
       " ('가', 'Josa'),\n",
       " ('잠', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('많이', 'Adverb'),\n",
       " ('잔다', 'Verb'),\n",
       " ('.', 'Punctuation')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = RegexpParser(\"\"\"\n",
    "    NP: {<Noun>{2,}<Josa>}\n",
    "    VP: {<Adverb><Verb><Punctuation>}\n",
    "\"\"\")\n",
    "grammer.parse(tokens).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The little yellow dog\n",
      "the cat\n"
     ]
    }
   ],
   "source": [
    "for _ in parseTree.subtrees():\n",
    "    if _.label() == \"NP\":\n",
    "        print(\" \".join([_[0] for _ in _.leaves()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구문분석 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번\n",
    "sentence = \"i shot an elephant in my pajamas.\"\n",
    "tokens = pos_tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = RegexpParser(\"\"\"\n",
    "    N: {<NN>}\n",
    "    Det: {<DT>|<PRP.+>}\n",
    "    V: {<V.*>}\n",
    "    P: {<IN>}\n",
    "    NP : {<PRP>|<Det><N>}\n",
    "    PP : {<P><NP>}\n",
    "    VP: {<V><NP>}\n",
    "    VP: {<VP><PP>}\n",
    "\"\"\")\n",
    "grammer.parse(tokens).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번\n",
    "sentence = \"the dog saw a man in the park\"\n",
    "tokens = pos_tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('dog', 'NN'),\n",
       " ('saw', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('man', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('park', 'NN')]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = RegexpParser(\"\"\"\n",
    "    N: {<NN>}\n",
    "    Det: {<DT>|<PRP.+>}\n",
    "    P: {<IN>}\n",
    "    NP: {<Det><N><PP>}\n",
    "    NP : {<Det><N>}\n",
    "    PP : {<P><NP>}\n",
    "    V: {<V.*>}\n",
    "    VP: {<V><NP>}\n",
    "    VP: {<VP><PP>}\n",
    "\"\"\")\n",
    "grammer.parse(tokens).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3번\n",
    "sentence = \"the angry bear chased the frightened little squirrel\"\n",
    "tokens = pos_tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('angry', 'JJ'),\n",
       " ('bear', 'NN'),\n",
       " ('chased', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('frightened', 'JJ'),\n",
       " ('little', 'JJ'),\n",
       " ('squirrel', 'NN')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = RegexpParser(\"\"\"\n",
    "    N: {<NN>}\n",
    "    Adj: {<JJ>}\n",
    "    Nom: {<Adj><N>}\n",
    "    Nom: {<Adj><Nom>}\n",
    "    Det: {<DT>}\n",
    "    NP: {<Det><Nom>}\n",
    "    V: {<VBD>}\n",
    "    VP: {<V><NP>}\n",
    "    \n",
    "\"\"\")\n",
    "grammer.parse(tokens).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4번\n",
    "sentence = \"the little bear saw the fine fat trout in the brook\"\n",
    "\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "MODEL = \"../python_library/stanford-postagger-full-2018-10-16/models/english-bidirectional-distsim.tagger\"\n",
    "PARSER = \"../python_library/stanford-postagger-full-2018-10-16/stanford-postagger-3.9.2.jar\"\n",
    "pos = StanfordPOSTagger(MODEL, PARSER)\n",
    "\n",
    "tokens = pos.tag(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('bear', 'NN'),\n",
       " ('saw', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('fine', 'JJ'),\n",
       " ('fat', 'JJ'),\n",
       " ('trout', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('brook', 'NN')]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammer = RegexpParser(\"\"\"\n",
    "    N: {<NN>|<NNS>}\n",
    "    Adj: {<JJ>}\n",
    "    P: {<IN>}\n",
    "    Nom: {<N>|<Adj>{1,}<N>}\n",
    "    Det: {<DT>}\n",
    "    NP: {<Det><Nom>}\n",
    "    V: {<VBD>}\n",
    "    VP: {<V><NP>}\n",
    "    PP: {<P><NP>}\n",
    "    VP: {<VP><PP>}\n",
    "    \n",
    "\"\"\")\n",
    "grammer.parse(tokens).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
