{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.04\n",
    "## 조건부확률 P(A, B)/P(B) = P(A|B)\n",
    "### 결합확률을 알면 개별확률, 조건부 확률 둘다 찾을 수 있다.\n",
    "## 결합확률을 어떻게 구할거냐면 chain rule 적용해서 P(A|B, C,.. Z)P(B|C ... Z) ...\n",
    "## NAIVE BAYES\n",
    "## Bayes Theorm\n",
    "## mle는 경험만 가지고 측정한다. 사전확률을 추가해서 map로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData =[\n",
    "    (1, \"Chinese Beijing Chinese\", True),\n",
    "    (2, \"Chinese Chinese Shanhai\", True),\n",
    "    (3, \"Chinese Macao\", True),\n",
    "    (4, \"Tokyo Japan Chinese\", False)\n",
    "]\n",
    "\n",
    "testingData = \"\"\"\n",
    "정의용·서호·박지원 통일각에서 받아\n",
    "[서울신문]\n",
    "DJ 서거 다음날 조문단 파견과 대조 \n",
    "고착상태 남북 관계 그대로 반영 평가 \n",
    "“北, 남측에 전할 메시지 정리 안된 듯”\n",
    "\n",
    "김여정 제1부부장, 조화 전달 - 김정은 북한 국무위원장의 동생 김여정 노동당 선전선동부 제1부부장(오른쪽)이 12일 오후 이희호 여사 서거와 관련, 판문점 통일각에서 정의용 청와대 국가안보실장(가운데), 박지원 김대중평화센터 부이사장에게 김 위원장이 보내는 조화를 전달하고 있다. 2019.6.12 [통일부 제공] 연합뉴스\n",
    "김정은 북한 국무위원장의 동생 김여정 노동당 선전선동부 제1부부장이 이희호 여사 별세와 관련해 12일 조화와 조전을 남측에 전달했다.\n",
    "\n",
    "통일부는 이날 “북측이 통지문을 통해 김 위원장이 보내는 조의문과 조화를 이날 오후 5시 판문점 통일각에서 전달했다”며 “남측에서는 정의용 국가안보실장과 서호 통일부 차관, 장례위원회를 대표해 김대중평화센터 부이사장인 박지원 민주평화당 의원이 전달받았다”고 밝혔다.\n",
    "\n",
    "앞서 2009년 8월 18일 김대중 전 대통령이 서거했을 당시 북한은 바로 다음날인 19일 김정일 국방위원장 명의의 조전을 보낸 뒤 통지문을 보내 조문단 파견 의사를 전달했다. 하지만 이번에는 판문점 북측 지역에서 조의문과 조화를 전달하며 남북 관계가 고착된 현 상황을 그대로 반영했다는 평가다.\n",
    "\n",
    "당시 북한은 김 전 대통령 서거 사흘 뒤인 21일 김양건 노동당 통일전선부장 겸 조선아시아태평양평화위원회 위원장, 김기남 노동당 중앙위원회 비서 등 6명으로 이뤄진 조문단을 파견했다. 이들은 고려항공 특별기편으로 김포공항에 도착하자마자 김 전 대통령의 빈소에 조문했다.\n",
    "\n",
    "김여정 제1부부장, 조전 전달 - 김정은 북한 국무위원장의 동생 김여정 노동당 선전선동부 제1부부장(오른쪽)이 12일 오후 이희호 여사 서거와 관련, 판문점 통일각에서 정의용 청와대 국가안보실장(왼쪽), 서호 통일부 차관, 박지원 김대중평화센터 부이사장에게 김 위원장이 보내는 조전을 전달하고 있다. 2019.6.12 [통일부 제공]\n",
    "조문단은 당시 2박 3일간 일정으로 머물면서 ‘대남 특사’의 역할을 수행했다. 이들은 빈소에 들른 뒤 김형오 국회의장을 예방하고 김대중평화센터가 주최한 만찬에 참석했다. 다음날에는 정세균 당시 민주당 대표와 만나고 현인택 통일부 장관과 면담했다. 또 마지막 날 이명박 전 대통령과의 면담도 전격적으로 성사돼 30분간 면담을 진행했다.\n",
    "\n",
    "이희호 여사는 2011년 12월 김정일 국방위원장 사망 당시 북한으로 직접 건너가 김 위원장을 직접 만나 애도의 뜻을 표한 바 있다.\n",
    "\n",
    "이번에도 북한이 조문단을 파견한다면 지난 2월 하노이 북미 정상회담 결렬 이후에 지속된 소강상태를 ‘조의 정치’를 통해 돌파구를 마련할 수 있다는 점에서 북측 조문단 파견 여부가 관심사로 떠올랐지만, 북측은 조문단 파견 대신 조화와 조전을 보내 애도를 표명하는 방법을 선택했다. 여기에는 아직 입장 정리가 되지 않은 북측이 메시지를 갖고 나오기에는 시기적으로 이른감이 있다는 분석이 나온다.\n",
    "\n",
    "이우영 북한대학교대학원 교수는 “하노이 회담 결렬 이후 하반기에 승부를 걸고 있는 북한이 아직 내부에서 남측에 전할 메시지 정리가 안 돼 있는 상황인 것 같다”며 “메시지를 논의해야 할 문재인 대통령도 북유럽 순방에 나서 한국에 없다는 시기적인 문제도 복합적으로 작용했을 것”이라고 분석했다.\n",
    "\n",
    "임을출 경남대 극동문제연구소 교수는 “남북 모두 무게감 있는 인사들이 한자리에서 만난 만큼 비핵화 협상 과정에서 남북 공조 부분에 대한 논의가 제한적으로라도 이뤄졌을 수 있다”고 했다.\n",
    "\n",
    "다만 김 위원장의 동생인 김 제1부부장이 직접 조화와 조의문을 전달한 것은 남북관계 개선에 노력해온 이 여사에 대한 예우를 갖춘 것으로 해석된다.\n",
    "\n",
    "박지원 의원은 페이스북에 “북한 정부에서 우리 정부의 책임 있는 인사에게 조의문과 조화를 전달하겠다고 한 것은 하노이 북미 정상회담 이후 김 위원장이 도널드 트럼프 미국 대통령에게 보낸 친서와 함께 의미 있는 변화”라며 “이 여사의 서거와 기도가 남북 정부 간 고위급 대화로 남북 정상회담, 북미 정상회담의 물꼬가 트이는 계기를 만들어 줬다”고 했다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shanhai', 'beijing', 'tokyo', 'macao', 'chinese', 'japan']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = list(set(([term for _ in trainingData\n",
    "        for term in _[1].lower().split()])))\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(trainingData)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueData = [_ for _ in trainingData if _[2]]\n",
    "falseData = [_ for _ in trainingData if not _[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Chinese Beijing Chinese', True),\n",
       " (2, 'Chinese Chinese Shanhai', True),\n",
       " (3, 'Chinese Macao', True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "prior = list()\n",
    "\n",
    "        \n",
    "Tct = defaultdict(int)\n",
    "for data in trueData:  \n",
    "    Nc = len(trueData)\n",
    "    PriorC = Nc/N\n",
    "    for term in data[1].lower().split():\n",
    "        Tct[term] += 1\n",
    "\n",
    "_Tct = defaultdict(int)\n",
    "for data in falseData:  \n",
    "    _Nc = len(falseData)\n",
    "    _PriorC = _Nc/N\n",
    "    for term in data[1].lower().split():\n",
    "        _Tct[term] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'chinese': 5, 'beijing': 1, 'shanhai': 1, 'macao': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "condProbC = defaultdict(float)\n",
    "_condProbC = defaultdict(float)\n",
    "\n",
    "countSum = sum(Tct.values())\n",
    "_countSum = sum(_Tct.values())\n",
    "\n",
    "for term, freq in Tct.items():\n",
    "    condProbC[term] = (freq+1)/(countSum + len(V))\n",
    "\n",
    "for term, freq in _Tct.items():\n",
    "    _condProbC[term] = (freq+1)/(_countSum + len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSum, _countSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(float,\n",
       "             {'chinese': 0.42857142857142855,\n",
       "              'beijing': 0.14285714285714285,\n",
       "              'shanhai': 0.14285714285714285,\n",
       "              'macao': 0.14285714285714285}),\n",
       " defaultdict(float,\n",
       "             {'tokyo': 0.2222222222222222,\n",
       "              'japan': 0.2222222222222222,\n",
       "              'chinese': 0.2222222222222222}))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condProbC, _condProbC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False -5.898526551448713 0.0027434842249657062\n"
     ]
    }
   ],
   "source": [
    "# P(C)multi(P(Tct|C)) ===> log(P(C)) + SUM(P(Tct|C))\n",
    "from math import log, exp\n",
    "\n",
    "# Prior Probability\n",
    "result = log(PriorC)\n",
    "_result = log(_PriorC)\n",
    "\n",
    "# joint probability => conditional independence\n",
    "for term in testingData[1].lower().split():\n",
    "    # multi -> log sum\n",
    "    result += log((Tct[term]+1)/(countSum+len(V)))\n",
    "    _result += log((_Tct[term]+1)/(_countSum+len(V)))\n",
    "\n",
    "# optimal classfier\n",
    "if result > _result:\n",
    "    print(\"True\", result, exp(result))\n",
    "else:\n",
    "    print(\"False\", _result, exp(_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42857142857142855, 0.2222222222222222, 0.2222222222222222)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condProbC[\"chinese\"], _condProbC[\"chinese\"], _condProbC[\"tokyo\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn 뉴스데이터 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a404c9c904a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnewsdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfetch_20newsgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewsdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnewsdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsdata=fetch_20newsgroups(subset='train')\n",
    "print(newsdata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 11314 20 11314\n"
     ]
    }
   ],
   "source": [
    "print (len(newsdata.data), len(newsdata.filenames), len(newsdata.target_names), len(newsdata.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.target[0])\n",
    "print(newsdata.target_names[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tdmvector = CountVectorizer()\n",
    "X_train_tdm = tdmvector.fit_transform(newsdata.data)\n",
    "\n",
    "print(X_train_tdm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(X_train_tdm)\n",
    "print(X_train_tdm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tdm[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # 다항분포 나이브 베이즈 모델\n",
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, newsdata.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7738980350504514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score #정확도 계산을 위한 함수\n",
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True) #테스트 데이터 갖고오기\n",
    "X_test_tdm = tdmvector.transform(newsdata_test.data) #테스트 데이터를 TDM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(X_test_tdm) #TDM을 TF-IDF 행렬로 변환\n",
    "\n",
    "predicted = mod.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(newsdata_test.target, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
