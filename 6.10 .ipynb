{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4차산업혁명 데이터 - 키워드 도출\n",
    "\n",
    "## 제목, 기사 끄내서 형태소 분석 먼저 하기 - 명사만 끄내고 불용어 제거(준 it사전으로)\n",
    "## IT / NON IT 나누고 \n",
    "## IT에서 세부 주제들 찾아내기\n",
    "### 1. 가상현실 / C_ITS / 공유플랫폼 / 드론 / 로봇 / 메이커스페이스 / 바이오헬스케어 / 블록체인 / 서비스디자인 / 스마트공장\n",
    "###    스마트기업지원 / 원도심재생 / 항만스마트물류 / 핵심기술센터 혁신금융 / 혁신창업  각 키워드 연관검색어 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "df = pd.DataFrame(columns=['idx', 'url', 'title', 'date', 'article'])\n",
    "\n",
    "for file in ['../python_library/자연어데이터/신문기사데이터/' + _ for _ in listdir('../python_library/자연어데이터/신문기사데이터/')][1:]:\n",
    "    c = pd.read_excel(file)\n",
    "    c.columns = ['idx', 'url', 'title', 'date', 'article']\n",
    "    df = pd.concat([df, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['article'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'하현회 LG유플러스 부회장이 21일 서울 용산구 LG유플러스 본사에서 열린 걱정없는 데이터요금제 출시 기념 기자간담회에서 인사말을 하고 있다. /연합뉴스LG유플러스가 21일 신규 요금제 6종을 출시했다.새 요금제는 월 7만원대 완전 무제한 LTE 데이터 요금제 1종, 월 4만∼6만원대 속도 제한 데이터 요금제 4종, 월정액 3만원대 데이터 요금제 1종으로 구성됐다. 모두 문자와 음성은 기본으로 제공한다. 우선 \\'속도 용량 걱정없는 데이터 78\\'은 월 7만8천원에 속도와 용량 제한 없이 데이터를 무제한 쓸 수 있다. 3사 완전 무제한 요금제 중 가장 저렴한 수준이다. 영화, 음악 등 1만5천원 상당의 콘텐츠도 추가로 이용하고, 데이터는 매월 15GB를 나눠쓸 수 있다. \\'추가 요금 걱정없는 데이터 69\\'는 월 6만9천원에 매일 5GB씩 월 최대 155GB(31일 기준)의 데이터를 제공한다. 하루 기본 데이터를 초과하더라도 5Mbps 속도로 데이터를 계속 쓸 수 있다. 5Mbps는 HD급 고화질 영상을 볼 수 있는 수준이다. 데이터는 매월 11GB 나눠쓸 수 있다.이 요금제는 SK텔레콤, KT의 경쟁 요금제와 가격이 같지만 데이터 제공량은 최대 55GB 많다. 하루 데이터 제공량 5GB는 데이터를 많이 쓰는 고객의 평균 사용량을 토대로 결정했다는 게 LG유플러스의 설명이다. \\'추가 요금 걱정없는 데이터 59\\'(월 5만9천원)와 \\'데이터 49\\'(월 4만9천원)는 기본 제공 데이터가 각각 6.6GB와 3GB이며, 이를 소진한 뒤에는 1Mbps(SD급 화질) 속도로 데이터를 계속 제공한다. LG유플러스는 \"데이터 59는 해비 유저와 소량 이용자 사이 고객층에 합리적 대안이 될 전망\"이라고 기대했다.\\'데이터 44\\'는 통신 3사의 속도 제한 데이터 요금제 중 최저가 상품이다. 월 4만4천원에 데이터 2.3GB를 기본 제공하고 데이터 소진 후에는 400Kbps 속도로 카카오톡, 이메일 등의 서비스를 계속 이용하게 한다.LG유플러스는 월 3만3천원에 데이터 1.3GB와 부가통화 110분을 제공하는 \\'LTE 데이터 33\\'도 선보였다. 기존 동일한 수준의 자사 요금제보다 데이터 제공량을 4.4배 늘려 3사 중 가장 많은 데이터를 제공한다. 1.3GB는 기존 자사 3만~4만원대 요금제 사용자의 평균 데이터 사용량이라고 LG유플러스는 설명했다.이 요금제는 25% 요금할인을 적용하면 월 2만4천원대에 이용 가능해 정부가 추진 중인 보편요금제(월 2만원대에 1GB, 음성통화 200분 이상) 수준에 부합한다. /양형종 기자\\xa0yanghj@kyeongin.com'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "def makePattern():\n",
    "    pattern = dict()\n",
    "\n",
    "    # 구두점\n",
    "    pattern1 = re.compile(r'[{0}]'.format(re.escape(punctuation)))\n",
    "    pattern['punc'] = pattern1\n",
    "    # corpus = pattern1.sub(' ',corpus)\n",
    "\n",
    "    # 불용어\n",
    "    pattern2 = re.compile(r'[A-Za-z0-9]{7,}')\n",
    "    pattern['stop'] = pattern2\n",
    "    # corpus = pattern2.sub(' ',corpus)\n",
    "\n",
    "    # 이메일\n",
    "    # pattern3 = re.compile(r'\\w{2,}@\\w{3,}(.\\w{2,})+')\n",
    "    pattern3 = re.compile(r'\\w{2,}@(.?\\w{2,})+')\n",
    "    pattern['email'] = pattern3\n",
    "    # corpus = pattern3.sub(' ',corpus)\n",
    "\n",
    "    # 도메인\n",
    "    pattern4 = re.compile(r'(.?\\w{2,}){2,}')\n",
    "    pattern['url'] = pattern4\n",
    "    # corpus = pattern4.sub(' ',corpus)\n",
    "\n",
    "    # 한글 이외\n",
    "    pattern5 = re.compile(r'[^가-힣0-9]+')\n",
    "    pattern['nonkorean'] = pattern5\n",
    "    # corpus = pattern5.sub(' ',corpus)\n",
    "\n",
    "    # WhiteSpace\n",
    "    pattern6 = re.compile(r\"\\s{2,}\")\n",
    "    pattern['whitespace'] = pattern5\n",
    "    # corpus = pattern6.sub(' ',corpus)\n",
    "    \n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# content = filecontent(fileids('./news_crawl_project/')[-2])\n",
    "\n",
    "pattern = makePattern()\n",
    "\n",
    "def punc_stop(file):\n",
    "    for _ in ['email', 'punc', 'stop','whitespace']:\n",
    "        try:\n",
    "            file = pattern[_].sub(' ',file)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "    return file\n",
    "\n",
    "def indexing(file):\n",
    "    indexTerm1 = defaultdict(int)\n",
    "    indexTerm2 = defaultdict(int)\n",
    "    indexTerm3 = defaultdict(int)\n",
    "    indexTerm4 = defaultdict(int)\n",
    "#     indexTerm5 = defaultdict(int)\n",
    "#     indexTerm6 = defaultdict(int)\n",
    "\n",
    "    for term in word_tokenize(file):\n",
    "        indexTerm1[term] += 1 # 원시어절\n",
    "    \n",
    "    for _ in indexTerm1:\n",
    "        for t in ma.pos(_):\n",
    "            indexTerm2[t] += 1 # 원시형태소+품사\n",
    "            if len(t[0]) > 1: # 음절 길이로 정규화\n",
    "                indexTerm3[t[0]] += 1 # 원시형태소\n",
    "            if t[1].startswith('N'):\n",
    "                indexTerm4[t[0]] += 1 # 명사\n",
    "#             for n in ngram(t[0]): # 바이그램\n",
    "#                 indexTerm5[n] += 1\n",
    "#                 indexTerm6[n] += 1\n",
    "    \n",
    "    return indexTerm4 #일단은 명사만 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 진행중\n",
      "200 진행중\n",
      "300 진행중\n",
      "400 진행중\n",
      "500 진행중\n",
      "600 진행중\n",
      "700 진행중\n",
      "800 진행중\n",
      "900 진행중\n",
      "1000 진행중\n",
      "1100 진행중\n",
      "1200 진행중\n",
      "1300 진행중\n",
      "1400 진행중\n",
      "1500 진행중\n",
      "1600 진행중\n",
      "1700 진행중\n",
      "1800 진행중\n",
      "1900 진행중\n",
      "2000 진행중\n",
      "2100 진행중\n",
      "2200 진행중\n",
      "2300 진행중\n",
      "2400 진행중\n",
      "2500 진행중\n",
      "2600 진행중\n",
      "2700 진행중\n",
      "2800 진행중\n",
      "2900 진행중\n",
      "3000 진행중\n",
      "3100 진행중\n",
      "3200 진행중\n",
      "3300 진행중\n",
      "3400 진행중\n",
      "3500 진행중\n",
      "3600 진행중\n",
      "3700 진행중\n",
      "3800 진행중\n",
      "3900 진행중\n",
      "4000 진행중\n",
      "4100 진행중\n",
      "4200 진행중\n",
      "4300 진행중\n",
      "4400 진행중\n",
      "4500 진행중\n",
      "4600 진행중\n",
      "4700 진행중\n",
      "4800 진행중\n",
      "4900 진행중\n",
      "5000 진행중\n",
      "5100 진행중\n",
      "5200 진행중\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "ma = Komoran()\n",
    "\n",
    "def DTM_conversion():\n",
    "    documentList = defaultdict(lambda: defaultdict(int))\n",
    "    idx = 0\n",
    "    for content in df:\n",
    "        documentList[idx] = indexing(punc_stop(content))\n",
    "        idx += 1\n",
    "        if idx % 100 == 0:\n",
    "            print(idx, '진행중')\n",
    "    return documentList\n",
    "DTM = DTM_conversion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IT 단어사전으로 IT / NON IT 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "for file in ['../python_library/자연어데이터/사전정보/' + _ for _ in listdir('../python_library/자연어데이터/사전정보/') if _.startwith('it')]:\n",
    "    with open(file, encoding='utf-8') as fp:\n",
    "        content = fp.read()\n",
    "\n",
    "\n",
    "def TQM_conversion(query):\n",
    "    \n",
    "    indexTerm1 = defaultdict(int)\n",
    "    indexTerm2 = defaultdict(int)\n",
    "    indexTerm3 = defaultdict(int)\n",
    "    indexTerm4 = defaultdict(int)\n",
    "    indexTerm5 = defaultdict(int)\n",
    "    indexTerm6 = defaultdict(int)\n",
    "\n",
    "    for _ in word_tokenize(query):\n",
    "        for t in ma.pos(_):\n",
    "            indexTerm2[t] += 1 # 원시형태소+품사\n",
    "            if len(t[0]) > 1: # 음절 길이로 정규화\n",
    "                indexTerm3[t[0]] += 1 # 원시형태소\n",
    "            if t[1].startswith('N'):\n",
    "                indexTerm4[t[0]] += 1 # 명사\n",
    "            for n in ngram(t[0]): # 바이그램\n",
    "                indexTerm5[n] += 1\n",
    "                indexTerm6[n] += 1\n",
    "    return indexTerm4\n",
    "\n",
    "query = '서울시에 거래되는 아파트의 전세값은?'\n",
    "TQM = TQM_conversion(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
